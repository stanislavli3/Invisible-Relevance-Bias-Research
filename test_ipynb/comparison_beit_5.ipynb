{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from timm.data.mixup import Mixup\n", "from timm.models import create_model\n", "from timm.utils import ModelEma"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from PIL import Image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "from tqdm import tqdm"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import XLMRobertaTokenizer\n", "from torchvision import transforms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "sys.path.append(\"/data/houdanyang/code/unilm/beit3/\")\n", "import modeling_finetune\n", "import utils"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_text_segment(text_segment, tokenizer, max_len):\n", "    tokens = tokenizer.tokenize(text_segment)\n", "    tokens = tokenizer.convert_tokens_to_ids(tokens)\n", "    if len(tokens) == 0:\n", "        raise RuntimeError(\"The text segment should contains at least one tokens!\")\n", "    if len(tokens) > max_len - 2:\n", "        tokens = tokens[:max_len - 2]\n", "    tokens = [tokenizer.bos_token_id] + tokens[:] + [tokenizer.eos_token_id]\n", "    num_tokens = len(tokens)\n", "    padding_mask = [0] * num_tokens + [1] * (max_len - num_tokens)\n", "    return tokens + [tokenizer.pad_token_id] * (max_len - num_tokens), padding_mask"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_retrieval(text_feature, image_feature, gt):\n", "    similarities = text_feature @ image_feature.t()\n", "    topk = similarities.topk(10)[1]\n", "    topk_correct = topk == gt\n", "    rank1 = topk_correct[:, :1].sum() / text_image_similarities.shape[0]\n", "    rank3 = topk_correct[:, :3].sum() / text_image_similarities.shape[0]\n", "    rank5 = topk_correct[:, :5].sum() / text_image_similarities.shape[0]\n", "    return rank1, rank3, rank5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_retrieval_ndcg(text_feature, image_feature, gt):\n", "    similarities = text_feature @ image_feature.t()\n", "    log = torch.log2(torch.arange(2, 12).cuda())\n", "    topk = similarities.topk(10)[1]\n", "    topk_correct = topk == gt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    dcg_r = topk_correct / log.unsqueeze(0)\n", "    dcg1_r = dcg_r[:,:1].sum(1)\n", "    dcg3_r = dcg_r[:, :3].sum(1)\n", "    dcg5_r = dcg_r[:, :5].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg1 = (dcg1_r / idcg).mean()\n", "    ndcg3 = (dcg3_r / idcg).mean()\n", "    ndcg5 = (dcg5_r / idcg).mean()\n", "    return ndcg1, ndcg3, ndcg5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_DCG(text_feature, image_feature, image_feature_generated, gt, gt_generated):\n", "    #print('text feature ',text_feature.shape)\n", "    #print('image feature ',image_feature.shape)\n", "    #print('image feature generated  ',image_feature_generated.shape)\n", "    image_feature_ = torch.concat([image_feature, image_feature_generated])\n", "    #print('image feature concat ', image_feature_.shape)\n", "    similarities = text_feature @ image_feature_.t()\n", "    #print('similarities ',similarities.shape)\n", "    topk = similarities.topk(10)[1]\n", "    #print('topk ',topk.shape)\n", "    #print(topk)\n", "    topk_correct = (topk == gt).type(torch.int)\n", "    #print('topk_correct ',topk_correct)\n", "    topk_correct_generated = (topk == gt_generated).type(torch.int)\n", "    #print('topk_correct_generated ',topk_correct_generated)\n", "    topk_correct_real_generated = topk_correct + topk_correct_generated\n", "    #print('topk_correct_real_generated ',topk_correct_real_generated)\n", "    log = torch.log2(torch.arange(2, 12).cuda())\n", "    dcg = topk_correct_real_generated / log.unsqueeze(0)\n", "    dcg5 = dcg[:,:5].sum(1)\n", "    dcg10 = dcg[:, :10].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg5 = (dcg5 / idcg).mean()\n", "    ndcg10 = (dcg10 / idcg).mean()\n", "    r2 = (topk_correct_real_generated[:, :2].sum(1) == 2).sum()/text_feature.shape[0]\n", "    r5 = (topk_correct_real_generated[:, :5].sum(1) == 2).sum()/text_feature.shape[0]\n", "    r10 = (topk_correct_real_generated[:, :10].sum(1) == 2).sum()/text_feature.shape[0]\n", "    ranks = similarities.sort(descending=True)[1]\n", "    ranks_real = (ranks == torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1,ranks.shape[1]).cuda()).nonzero()[:,1]\n", "    ranks_generated = (ranks == torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1,ranks.shape[1]).cuda() + text_image_similarities.shape[0]).nonzero()[:,1]\n", "    mask_100 = ((ranks_real < 100) * (ranks_generated < 100))\n", "    rank_differences = ((ranks_real - ranks_generated) * mask_100).sum()/ mask_100.sum()\n\n", "    ##############compute reletavie delta###############\n", "    r1_r = topk_correct[:, :1].sum() / text_image_similarities.shape[0]\n", "    r3_r = topk_correct[:, :3].sum() / text_image_similarities.shape[0]\n", "    r5_r = topk_correct[:, :5].sum() / text_image_similarities.shape[0]\n", "    r1_g = topk_correct_generated[:, :1].sum() / text_image_similarities.shape[0]\n", "    r3_g = topk_correct_generated[:, :3].sum() / text_image_similarities.shape[0]\n", "    r5_g = topk_correct_generated[:, :5].sum() / text_image_similarities.shape[0]\n", "    reletive_r1_g = 2*(r1_r.item()-r1_g.item()) / (r1_r.item()+r1_g.item())\n", "    reletive_r3_g = 2*(r3_r.item()-r3_g.item()) / (r3_r.item()+r3_g.item())\n", "    reletive_r5_g = 2*(r5_r.item()-r5_g.item()) / (r5_r.item()+r5_g.item())\n", "    print(\" r_delta@1: {},\\n r_delta@3: {}, \\n r_delta@5: {}\".format(round(reletive_r1_g * 100,2), round(reletive_r3_g * 100,2), round(reletive_r5_g * 100,2)))\n", "    log = torch.log2(torch.arange(2, 12).cuda())\n", "    dcg_r = topk_correct / log.unsqueeze(0)\n", "    dcg1_r = dcg_r[:,:1].sum(1)\n", "    dcg3_r = dcg_r[:, :3].sum(1)\n", "    dcg5_r = dcg_r[:, :5].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg1_r = (dcg1_r / idcg).mean()\n", "    ndcg3_r = (dcg3_r / idcg).mean()\n", "    ndcg5_r = (dcg5_r / idcg).mean()\n", "    dcg_g = topk_correct_generated / log.unsqueeze(0)\n", "    dcg1_g = dcg_g[:,:1].sum(1)\n", "    dcg3_g = dcg_g[:, :3].sum(1)\n", "    dcg5_g = dcg_g[:, :5].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg1_g = (dcg1_g / idcg).mean()\n", "    ndcg3_g = (dcg3_g / idcg).mean()\n", "    ndcg5_g = (dcg5_g / idcg).mean()\n", "    reletive_n1_g = 2*(ndcg1_r.item()-ndcg1_g.item()) / (ndcg1_r.item()+ndcg1_g.item())\n", "    reletive_n3_g = 2*(ndcg3_r.item()-ndcg3_g.item()) / (ndcg3_r.item()+ndcg3_g.item())\n", "    reletive_n5_g = 2*(ndcg5_r.item()-ndcg5_g.item()) / (ndcg5_r.item()+ndcg5_g.item())\n", "    print(\" ndcg_delta@1: {}, \\n ndcg_delta@3: {}, \\n ndcg_delta@5: {}\".format(round(reletive_n1_g * 100,2), round(reletive_n3_g * 100,2), round(reletive_n5_g * 100,2)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    return r2, r5, r10, ndcg5, ndcg10, rank_differences, \\\n", "           r1_r,r3_r,r5_r,r1_g,r3_g,r5_g, \\\n", "           ndcg1_r, ndcg3_r, ndcg5_r, ndcg1_g, ndcg3_g, ndcg5_g, \\\n", "           reletive_r1_g, reletive_r3_g, reletive_r5_g, \\\n", "           reletive_n1_g, reletive_n3_g, reletive_n5_g"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    transform = transforms.Compose([\n", "        transforms.Resize((384, 384), interpolation=3),\n", "        transforms.ToTensor(),\n", "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n", "    ])\n", "    model = create_model(\n", "        'beit3_large_patch16_384_retrieval',\n", "        pretrained=False,\n", "        drop_path_rate=0.1,\n", "        vocab_size=64010,\n", "    )\n", "    utils.load_model_and_may_interpolate(\"./beit3_large_itc_patch16_224.pth\", model, \"model|module\",\"\")\n", "    model.cuda()\n", "    model.eval()\n", "    tokenizer = XLMRobertaTokenizer(\"./beit3.spm\")\n", "    image_path = \"./flickr/flickr30k-images\"\n", "    image_path_generated = \"./flickr_merge/test_fp16_refiner_selected_30_open_clip_h14\"\n", "    data_save_path = \"./flickr_merge/selected_30_open_clip_h14_BEIT.json\"\n", "    file = \"./flickr/flickr30k_test.json\"\n", "    f = open(file)\n", "    data_list = json.load(f)\n", "    r1_sum, r3_sum, r5_sum = 0,0,0\n", "    r1_g_sum, r3_g_sum, r5_g_sum = 0,0,0\n", "    n1_sum, n3_sum, n5_sum = 0,0,0\n", "    n1_g_sum, n3_g_sum, n5_g_sum = 0,0,0\n", "    r1_sum_c, r3_sum_c, r5_sum_c = 0,0,0\n", "    r1_g_sum_c, r3_g_sum_c, r5_g_sum_c = 0,0,0\n", "    n1_sum_c, n3_sum_c, n5_sum_c = 0,0,0\n", "    n1_g_sum_c, n3_g_sum_c, n5_g_sum_c = 0,0,0\n", "    rank_differences_sum = 0\n", "    reletive_n1_g_sum, reletive_n3_g_sum, reletive_n5_g_sum = 0 ,0 , 0\n", "    reletive_r1_g_sum, reletive_r3_g_sum, reletive_r5_g_sum = 0, 0, 0\n", "    for cap_idx in range(5):\n", "        image_batch = []\n", "        image_batch_generated = []\n", "        text_batch = []\n", "        mask_batch = []\n", "        id_batch = []\n", "        batch_size = 256\n", "        image_feature = []\n", "        image_feature_generated = []\n", "        text_feature = []\n", "        text_image_similarities = []\n", "        selected_image = {}\n", "        with torch.no_grad():\n", "            for idx, line in tqdm(enumerate(data_list), desc=\"Computing Image Embeddings\", ncols=100, total=len(data_list)):\n", "                caption = line['caption'][cap_idx]\n", "                text, mask = get_text_segment(caption, tokenizer, 77)\n", "                text_batch.append(torch.tensor(text))\n", "                mask_batch.append(torch.tensor(mask))\n", "                image_file = line['image'].split('/')[-1]\n", "                image_batch.append(transform(Image.open(os.path.join(image_path, image_file)).convert(\"RGB\")))\n", "                image_batch_generated.append(\n", "                    transform(Image.open(os.path.join(image_path_generated, image_file)).convert(\"RGB\")))\n", "                selected_image[line['image']] = {\"text\": text, \"image\": image_file}\n", "                id_batch.append(line['image'])\n", "                if len(text_batch) % batch_size == 0 or idx == len(data_list) - 1:\n", "                    image_batch = torch.stack(image_batch).cuda()\n", "                    image_batch_generated = torch.stack(image_batch_generated).cuda()\n", "                    image_batch, _ = model(image=image_batch, only_infer=True)\n", "                    image_batch = image_batch / image_batch.norm(p=2, dim=-1, keepdim=True)\n", "                    image_batch_generated, _ = model(image=image_batch_generated, only_infer=True)\n", "                    image_batch_generated = image_batch_generated / image_batch_generated.norm(p=2, dim=-1, keepdim=True)\n", "                    image_feature.append(image_batch)\n", "                    image_feature_generated.append(image_batch_generated)\n", "                    text_batch = torch.stack(text_batch).cuda()\n", "                    mask_batch = torch.stack(mask_batch).cuda()\n", "                    _, text_batch = model(text_description=text_batch, padding_mask=mask_batch, only_infer=True)\n", "                    text_batch = text_batch / text_batch.norm(p=2, dim=-1, keepdim=True)\n", "                    text_feature.append(text_batch)\n", "                    text_image_similarity = (text_batch * image_batch).sum(-1)\n", "                    text_image_similarity_generated = (text_batch * image_batch_generated).sum(-1)\n", "                    similarities = torch.stack([text_image_similarity, text_image_similarity_generated], dim=-1)\n", "                    text_image_similarities.append(similarities)\n", "                    for id, similarity in zip(id_batch, similarities):\n", "                        selected_image[id][\"similarity\"] = similarity.tolist()\n", "                    image_batch = []\n", "                    image_batch_generated = []\n", "                    text_batch = []\n", "                    mask_batch = []\n", "                    id_batch = []\n", "        text_image_similarities = torch.concat(text_image_similarities)\n", "        generated_max_prob = text_image_similarities.max(-1)[1].sum() / text_image_similarities.shape[0]\n", "        print(generated_max_prob)\n", "        text_feature = torch.cat(text_feature)\n", "        image_feature = torch.cat(image_feature)\n", "        image_feature_generated = torch.cat(image_feature_generated)\n", "        gt = torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1, 10).cuda()\n", "        gt_generated = torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1, 10).cuda() + \\\n", "                       text_image_similarities.shape[0]\n", "        similarity_differences = text_image_similarities.mean(0)[1] - text_image_similarities.mean(0)[0]\n", "        r1, r3, r5 = evaluate_retrieval(text_feature, image_feature, gt)\n", "        r1_g, r3_g, r5_g = evaluate_retrieval(text_feature, image_feature_generated, gt)\n", "        r1_sum += r1\n", "        r3_sum += r3\n", "        r5_sum += r5\n", "        r1_g_sum += r1_g\n", "        r3_g_sum += r3_g\n", "        r5_g_sum += r5_g\n", "        print(\" r@1: {},\\n r@3: {},\\n r@5: {}\".format(round(r1.item(), 2), round(r3.item(), 2), round(r5.item(), 2)))\n", "        print(\" r_g@1: {},\\n r_g@3: {}, \\n r_g@5: {}\".format(round(r1_g.item(), 2), round(r3_g.item(), 2),\n", "                                                             round(r5_g.item(), 2)))\n", "        n1, n3, n5 = evaluate_retrieval_ndcg(text_feature, image_feature, gt)\n", "        n1_g, n3_g, n5_g = evaluate_retrieval_ndcg(text_feature, image_feature_generated, gt)\n", "        n1_sum += n1\n", "        n3_sum += n3\n", "        n5_sum += n5\n", "        n1_g_sum += n1_g\n", "        n3_g_sum += n3_g\n", "        n5_g_sum += n5_g\n", "        print(\" ndcg@1: {},\\n ndcg@3: {},\\n ndcg@5: {}\".format(round(n1.item(), 2), round(n3.item(), 2), round(n5.item(), 2)))\n", "        print(\" ndcg_g@1: {},\\n ndcg_g@3: {}, \\n ndcg_g@5: {}\".format(round(n1_g.item(), 2), round(n3_g.item(), 2),\n", "                                                             round(n5_g.item(), 2)))\n", "        r2_r_g, r5_r_g, r10_r_g, ndcg5, ndcg10, rank_differences, \\\n", "        r1_r_c, r3_r_c, r5_r_c, r1_g_c, r3_g_c, r5_g_c, \\\n", "        ndcg1_r_c, ndcg3_r_c, ndcg5_r_c, ndcg1_g_c, ndcg3_g_c, ndcg5_g_c, \\\n", "        reletive_r1_g, reletive_r3_g, reletive_r5_g, \\\n", "        reletive_n1_g, reletive_n3_g, reletive_n5_g, \\\n", "            = get_DCG(text_feature, image_feature, image_feature_generated, gt,\n", "                                                              gt_generated)\n", "        print(\"RankDiff: \", rank_differences.item())\n", "        rank_differences_sum += rank_differences\n", "        reletive_r1_g_sum += reletive_r1_g\n", "        reletive_r3_g_sum += reletive_r3_g\n", "        reletive_r5_g_sum += reletive_r5_g\n", "        reletive_n1_g_sum += reletive_n1_g\n", "        reletive_n3_g_sum += reletive_n3_g\n", "        reletive_n5_g_sum += reletive_n5_g\n", "        r1_sum_c += r1_r_c\n", "        r3_sum_c += r3_r_c\n", "        r5_sum_c += r5_r_c\n", "        r1_g_sum_c += r1_g_c\n", "        r3_g_sum_c += r3_g_c\n", "        r5_g_sum_c += r5_g_c\n", "        n1_sum_c += ndcg1_r_c\n", "        n3_sum_c += ndcg3_r_c\n", "        n5_sum_c += ndcg5_r_c\n", "        n1_g_sum_c += ndcg1_g_c\n", "        n3_g_sum_c += ndcg3_g_c\n", "        n5_g_sum_c += ndcg5_g_c\n", "    print('******************Five avg**************************:')\n", "    print(\"RankDiff: \", rank_differences_sum / 5)\n", "    print(\" r_delta@1: {},\\n r_delta@3: {}, \\n r_delta@5: {}\".\n", "          format(round(reletive_r1_g_sum * 100, 2) / 5, round(reletive_r3_g_sum * 100, 2) / 5,\n", "                 round(reletive_r5_g_sum * 100, 2) / 5))\n", "    print(\" ndcg_delta@1: {}, \\n ndcg_delta@3: {}, \\n ndcg_delta@5: {}\".\n", "          format(round(reletive_n1_g_sum * 100, 2) / 5, round(reletive_n3_g_sum * 100, 2) / 5,\n", "                 round(reletive_n5_g_sum * 100, 2) / 5))\n", "    print(\" r@1: {},\\n r@3: {},\\n r@5: {}\".format(r1_sum / 5, r3_sum / 5, r5_sum / 5))\n", "    print(\" r_g@1: {},\\n r_g@3: {}, \\n r_g@5: {}\".format(r1_g_sum / 5, r3_g_sum / 5,\n", "                                                         r5_g_sum / 5))\n", "    print(\" ndcg@1: {},\\n ndcg@3: {},\\n ndcg@5: {}\".format(n1_sum / 5, n3_sum / 5, n5_sum / 5))\n", "    print(\" ndcg_g@1: {},\\n ndcg_g@3: {}, \\n ndcg_g@5: {}\".format(n1_g_sum / 5, n3_g_sum / 5,\n", "                                                                  n5_g_sum / 5))\n", "    print(\" r@1_c: {},\\n r@3_c: {},\\n r@5_c: {}\".format(r1_sum_c / 5, r3_sum_c / 5, r5_sum_c / 5))\n", "    print(\" r_g@1_c: {},\\n r_g@3_c: {}, \\n r_g@5_c: {}\".format(r1_g_sum_c / 5, r3_g_sum_c / 5,\n", "                                                               r5_g_sum_c / 5))\n", "    print(\" ndcg@1_c: {},\\n ndcg@3_c: {},\\n ndcg@5_c: {}\".format(n1_sum_c / 5, n3_sum_c / 5, n5_sum_c / 5))\n", "    print(\" ndcg_g@1_c: {},\\n ndcg_g@3_c: {}, \\n ndcg_g@5_c: {}\".format(n1_g_sum_c / 5, n3_g_sum_c / 5,\n", "                                                                        n5_g_sum_c / 5))\n", "    f = open(data_save_path, 'w')\n", "    f.write(json.dumps(selected_image))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}