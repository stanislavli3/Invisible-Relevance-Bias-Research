{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "os.environ['CUDA_VISIBLE_DEVICES']='1'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from transformers import CLIPProcessor, CLIPModel\n", "from transformers import AlignProcessor, AlignModel\n", "from transformers import FlavaProcessor, FlavaModel\n", "from tqdm import tqdm\n", "import random\n", "from PIL import Image\n", "import json"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from plot_tsne import plot_tsne"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_retrieval(text_feature, image_feature, gt):\n", "    similarities = text_feature @ image_feature.t()\n", "    topk = similarities.topk(10)[1]\n", "    topk_correct = topk == gt\n", "    rank1 = topk_correct[:, :1].sum() / text_image_similarities.shape[0]\n", "    rank3 = topk_correct[:, :3].sum() / text_image_similarities.shape[0]\n", "    rank5 = topk_correct[:, :5].sum() / text_image_similarities.shape[0]\n", "    return rank1, rank3, rank5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate_retrieval_ndcg(text_feature, image_feature, gt):\n", "    similarities = text_feature @ image_feature.t()\n", "    log = torch.log2(torch.arange(2, 12).cuda())\n", "    topk = similarities.topk(10)[1]\n", "    topk_correct = topk == gt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    dcg_r = topk_correct / log.unsqueeze(0)\n", "    dcg1_r = dcg_r[:,:1].sum(1)\n", "    dcg3_r = dcg_r[:, :3].sum(1)\n", "    dcg5_r = dcg_r[:, :5].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg1 = (dcg1_r / idcg).mean()\n", "    ndcg3 = (dcg3_r / idcg).mean()\n", "    ndcg5 = (dcg5_r / idcg).mean()\n", "    return ndcg1, ndcg3, ndcg5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_DCG(text_feature, image_feature, image_feature_generated, gt, gt_generated):\n", "    #print('text feature ',text_feature.shape)\n", "    #print('image feature ',image_feature.shape)\n", "    #print('image feature generated  ',image_feature_generated.shape)\n", "    image_feature_ = torch.concat([image_feature, image_feature_generated])\n", "    #print('image feature concat ', image_feature_.shape)\n", "    similarities = text_feature @ image_feature_.t()\n", "    #print('similarities ',similarities.shape)\n", "    topk = similarities.topk(10)[1]\n", "    #print('topk ',topk.shape)\n", "    #print(topk)\n", "    topk_correct = (topk == gt).type(torch.int)\n", "    #print('topk_correct ',topk_correct)\n", "    topk_correct_generated = (topk == gt_generated).type(torch.int)\n", "    #print('topk_correct_generated ',topk_correct_generated)\n", "    topk_correct_real_generated = topk_correct + topk_correct_generated\n", "    #print('topk_correct_real_generated ',topk_correct_real_generated)\n", "    log = torch.log2(torch.arange(2, 12).cuda())\n", "    dcg = topk_correct_real_generated / log.unsqueeze(0)\n", "    dcg5 = dcg[:,:5].sum(1)\n", "    dcg10 = dcg[:, :10].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg5 = (dcg5 / idcg).mean()\n", "    ndcg10 = (dcg10 / idcg).mean()\n", "    r2 = (topk_correct_real_generated[:, :2].sum(1) == 2).sum()/text_feature.shape[0]\n", "    r5 = (topk_correct_real_generated[:, :5].sum(1) == 2).sum()/text_feature.shape[0]\n", "    r10 = (topk_correct_real_generated[:, :10].sum(1) == 2).sum()/text_feature.shape[0]\n", "    ranks = similarities.sort(descending=True)[1]\n", "    ranks_real = (ranks == torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1,ranks.shape[1]).cuda()).nonzero()[:,1]\n", "    ranks_generated = (ranks == torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1,ranks.shape[1]).cuda() + text_image_similarities.shape[0]).nonzero()[:,1]\n", "    mask_100 = ((ranks_real < 100) * (ranks_generated < 100))\n", "    rank_differences = ((ranks_real - ranks_generated) * mask_100).sum()/ mask_100.sum()\n\n", "    ##############compute reletavie delta###############\n", "    r1_r = topk_correct[:, :1].sum() / text_image_similarities.shape[0]\n", "    r3_r = topk_correct[:, :3].sum() / text_image_similarities.shape[0]\n", "    r5_r = topk_correct[:, :5].sum() / text_image_similarities.shape[0]\n", "    r1_g = topk_correct_generated[:, :1].sum() / text_image_similarities.shape[0]\n", "    r3_g = topk_correct_generated[:, :3].sum() / text_image_similarities.shape[0]\n", "    r5_g = topk_correct_generated[:, :5].sum() / text_image_similarities.shape[0]\n", "    reletive_r1_g = 2*(r1_r.item()-r1_g.item()) / (r1_r.item()+r1_g.item())\n", "    reletive_r3_g = 2*(r3_r.item()-r3_g.item()) / (r3_r.item()+r3_g.item())\n", "    reletive_r5_g = 2*(r5_r.item()-r5_g.item()) / (r5_r.item()+r5_g.item())\n", "    print(\" r_delta@1: {},\\n r_delta@3: {}, \\n r_delta@5: {}\".format(round(reletive_r1_g * 100,2), round(reletive_r3_g * 100,2), round(reletive_r5_g * 100,2)))\n", "    log = torch.log2(torch.arange(2, 12).cuda())\n", "    dcg_r = topk_correct / log.unsqueeze(0)\n", "    dcg1_r = dcg_r[:,:1].sum(1)\n", "    dcg3_r = dcg_r[:, :3].sum(1)\n", "    dcg5_r = dcg_r[:, :5].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg1_r = (dcg1_r / idcg).mean()\n", "    ndcg3_r = (dcg3_r / idcg).mean()\n", "    ndcg5_r = (dcg5_r / idcg).mean()\n", "    dcg_g = topk_correct_generated / log.unsqueeze(0)\n", "    dcg1_g = dcg_g[:,:1].sum(1)\n", "    dcg3_g = dcg_g[:, :3].sum(1)\n", "    dcg5_g = dcg_g[:, :5].sum(1)\n", "    idcg = (1 / log[:2]).sum()\n", "    ndcg1_g = (dcg1_g / idcg).mean()\n", "    ndcg3_g = (dcg3_g / idcg).mean()\n", "    ndcg5_g = (dcg5_g / idcg).mean()\n", "    reletive_n1_g = 2*(ndcg1_r.item()-ndcg1_g.item()) / (ndcg1_r.item()+ndcg1_g.item())\n", "    reletive_n3_g = 2*(ndcg3_r.item()-ndcg3_g.item()) / (ndcg3_r.item()+ndcg3_g.item())\n", "    reletive_n5_g = 2*(ndcg5_r.item()-ndcg5_g.item()) / (ndcg5_r.item()+ndcg5_g.item())\n", "    print(\" ndcg_delta@1: {}, \\n ndcg_delta@3: {}, \\n ndcg_delta@5: {}\".format(round(reletive_n1_g * 100,2), round(reletive_n3_g * 100,2), round(reletive_n5_g * 100,2)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    return r2, r5, r10, ndcg5, ndcg10, rank_differences, \\\n", "           r1_r,r3_r,r5_r,r1_g,r3_g,r5_g, \\\n", "           ndcg1_r, ndcg3_r, ndcg5_r, ndcg1_g, ndcg3_g, ndcg5_g, \\\n", "           reletive_r1_g, reletive_r3_g, reletive_r5_g, \\\n", "           reletive_n1_g, reletive_n3_g, reletive_n5_g"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    image_path = \"./flickr/flickr30k-images\"\n", "    image_path_generated = \"./flickr_merge/test_fp16_refiner_selected_30_open_clip_h14\"\n", "    data_save_path = \"./flickr_merge/selected_30_open_clip_h14_CLIP_chatgpt_selected.json\"\n", "    model = FlavaModel.from_pretrained(\"facebook/flava-full\").cuda()\n", "    preprocesor = FlavaProcessor.from_pretrained(\"facebook/flava-full\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    file = \"./flickr/flickr30k_test.json\"\n", "    f = open(file)\n", "    data_list = json.load(f)\n", "    r1_sum, r3_sum, r5_sum = 0,0,0\n", "    r1_g_sum, r3_g_sum, r5_g_sum = 0,0,0\n", "    n1_sum, n3_sum, n5_sum = 0,0,0\n", "    n1_g_sum, n3_g_sum, n5_g_sum = 0,0,0\n", "    r1_sum_c, r3_sum_c, r5_sum_c = 0,0,0\n", "    r1_g_sum_c, r3_g_sum_c, r5_g_sum_c = 0,0,0\n", "    n1_sum_c, n3_sum_c, n5_sum_c = 0,0,0\n", "    n1_g_sum_c, n3_g_sum_c, n5_g_sum_c = 0,0,0\n", "    rank_differences_sum = 0\n", "    reletive_n1_g_sum, reletive_n3_g_sum, reletive_n5_g_sum = 0 ,0 , 0\n", "    reletive_r1_g_sum, reletive_r3_g_sum, reletive_r5_g_sum = 0, 0, 0\n", "    for cap_idx in range(5):\n", "        image_batch = []\n", "        image_batch_generated = []\n", "        text_batch = []\n", "        id_batch = []\n", "        batch_size = 128\n", "        text_image_similarities = []\n", "        selected_image = {}\n", "        image_feature = []\n", "        image_feature_generated = []\n", "        text_feature = []\n", "        model.eval()\n", "        #data_list = f.readlines()\n", "        with torch.no_grad():\n", "            for idx, line in tqdm(enumerate(data_list), desc=\"Computing Image Embeddings\", ncols=100, total=len(data_list)):\n", "                caption = line['caption'][cap_idx]\n", "                text_batch.append(caption)\n", "                image_file = line['image'].split('/')[-1]\n", "                image_batch.append(preprocesor.image_processor(Image.open(os.path.join(image_path, image_file)).convert(\"RGB\"), return_tensors='pt').data['pixel_values'][0])\n", "                image_batch_generated.append(preprocesor.image_processor(Image.open(os.path.join(image_path_generated, image_file)).convert(\"RGB\"), return_tensors='pt').data['pixel_values'][0])\n", "                selected_image[image_file] = {\"text\": caption, \"image\": image_file}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                id_batch.append(image_file)\n", "                if len(text_batch) % batch_size == 0 or idx == len(data_list) - 1 :\n", "                    image_batch = torch.stack(image_batch).cuda()\n", "                    image_batch_generated = torch.stack(image_batch_generated).cuda()\n", "                    image_batch = model.get_image_features(image_batch)\n", "                    #image_batch = image_batch / image_batch.norm(p=2, dim=-1, keepdim=True)\n", "                    image_batch = image_batch[:, 0] #flava\n", "                    image_batch_generated = model.get_image_features(image_batch_generated)\n", "                    image_batch_generated = image_batch_generated[:,0] #flava\n", "                    #image_batch_generated = image_batch_generated / image_batch_generated.norm(p=2, dim=-1, keepdim=True)\n", "                    image_feature.append(image_batch)\n", "                    image_feature_generated.append(image_batch_generated)\n", "                    text_batch = preprocesor.tokenizer(text_batch, padding=True, max_length=77,truncation=True, return_tensors=\"pt\").data\n", "                    attn_mask = text_batch['attention_mask'].cuda()\n", "                    text_batch = text_batch['input_ids'].cuda()\n", "                    text_batch = model.get_text_features(text_batch, attn_mask)\n", "                    text_batch = text_batch[:, 0] #flava\n", "                    #text_batch = text_batch / text_batch.norm(p=2, dim=-1, keepdim=True)\n", "                    text_feature.append(text_batch)\n", "                    text_image_similarity = (text_batch * image_batch).sum(-1)\n", "                    text_image_similarity_generated = (text_batch * image_batch_generated).sum(-1)\n", "                    similarities = torch.stack([text_image_similarity, text_image_similarity_generated], dim=-1)\n", "                    image_image_similarities = (image_batch * image_batch_generated).sum(-1)\n", "                    text_image_similarities.append(similarities)\n", "                    for id, similarity, image_image_similarity in zip(id_batch, similarities, image_image_similarities):\n", "                        selected_image[id][\"similarity\"] = similarity.tolist()\n", "                        selected_image[id][\"image_image_similarity\"] = image_image_similarity.item()\n", "                    image_batch = []\n", "                    image_batch_generated = []\n", "                    text_batch = []\n", "                    id_batch = []\n", "        text_image_similarities = torch.concat(text_image_similarities)\n", "        generated_max_prob = text_image_similarities.max(-1)[1].sum()/text_image_similarities.shape[0]\n", "        print(generated_max_prob)\n", "        text_feature = torch.cat(text_feature)\n", "        image_feature = torch.cat(image_feature)\n", "        image_feature_generated = torch.cat(image_feature_generated)\n", "        feat = torch.cat([image_feature, image_feature_generated, text_feature]).cpu().numpy()\n", "        label_test1 = [0 for index in range(1000)]\n", "        label_test2 = [1 for index in range(1000)]\n", "        label_test3 = [2 for index in range(1000)]\n", "        labels = np.array(label_test1 + label_test2 + label_test3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        plot_tsne(feat, labels)\n", "        gt = torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1, 10).cuda()\n", "        gt_generated = torch.arange(text_image_similarities.shape[0]).unsqueeze(-1).repeat(1, 10).cuda() + \\\n", "                       text_image_similarities.shape[0]\n", "        similarity_differences = text_image_similarities.mean(0)[1] - text_image_similarities.mean(0)[0]\n", "        r1,r3,r5 = evaluate_retrieval(text_feature, image_feature, gt)\n", "        r1_g, r3_g, r5_g = evaluate_retrieval(text_feature, image_feature_generated, gt)\n", "        r1_sum += r1\n", "        r3_sum += r3\n", "        r5_sum += r5\n", "        r1_g_sum += r1_g\n", "        r3_g_sum += r3_g\n", "        r5_g_sum += r5_g\n", "        print(\" r@1: {},\\n r@3: {},\\n r@5: {}\".format(round(r1.item(),2), round(r3.item(),2), round(r5.item(),2)))\n", "        print(\" r_g@1: {},\\n r_g@3: {}, \\n r_g@5: {}\".format(round(r1_g.item(),2), round(r3_g.item(),2), round(r5_g.item(),2)))\n", "        n1, n3, n5 = evaluate_retrieval_ndcg(text_feature, image_feature, gt)\n", "        n1_g, n3_g, n5_g = evaluate_retrieval_ndcg(text_feature, image_feature_generated, gt)\n", "        n1_sum += n1\n", "        n3_sum += n3\n", "        n5_sum += n5\n", "        n1_g_sum += n1_g\n", "        n3_g_sum += n3_g\n", "        n5_g_sum += n5_g\n", "        print(\" ndcg@1: {},\\n ndcg@3: {},\\n ndcg@5: {}\".format(round(n1.item(), 2), round(n3.item(), 2), round(n5.item(), 2)))\n", "        print(\" ndcg_g@1: {},\\n ndcg_g@3: {}, \\n ndcg_g@5: {}\".format(round(n1_g.item(), 2), round(n3_g.item(), 2),\n", "                                                             round(n5_g.item(), 2)))\n", "        r2_r_g, r5_r_g, r10_r_g, ndcg5, ndcg10, rank_differences, \\\n", "        r1_r_c, r3_r_c, r5_r_c, r1_g_c, r3_g_c, r5_g_c, \\\n", "        ndcg1_r_c, ndcg3_r_c, ndcg5_r_c, ndcg1_g_c, ndcg3_g_c, ndcg5_g_c, \\\n", "        reletive_r1_g, reletive_r3_g, reletive_r5_g, \\\n", "        reletive_n1_g, reletive_n3_g, reletive_n5_g, \\\n", "            = get_DCG(text_feature, image_feature, image_feature_generated, gt,\n", "                      gt_generated)\n", "        print(\"RankDiff: \", rank_differences.item())\n", "        rank_differences_sum += rank_differences\n", "        reletive_r1_g_sum += reletive_r1_g\n", "        reletive_r3_g_sum += reletive_r3_g\n", "        reletive_r5_g_sum += reletive_r5_g\n", "        reletive_n1_g_sum += reletive_n1_g\n", "        reletive_n3_g_sum += reletive_n3_g\n", "        reletive_n5_g_sum += reletive_n5_g\n", "        r1_sum_c += r1_r_c\n", "        r3_sum_c += r3_r_c\n", "        r5_sum_c += r5_r_c\n", "        r1_g_sum_c += r1_g_c\n", "        r3_g_sum_c += r3_g_c\n", "        r5_g_sum_c += r5_g_c\n", "        n1_sum_c += ndcg1_r_c\n", "        n3_sum_c += ndcg3_r_c\n", "        n5_sum_c += ndcg5_r_c\n", "        n1_g_sum_c += ndcg1_g_c\n", "        n3_g_sum_c += ndcg3_g_c\n", "        n5_g_sum_c += ndcg5_g_c\n", "    print('******************Five avg**************************:')\n", "    print(\"RankDiff: \", rank_differences_sum / 5)\n", "    print(\" r_delta@1: {},\\n r_delta@3: {}, \\n r_delta@5: {}\".\n", "          format(round(reletive_r1_g_sum * 100, 2) / 5, round(reletive_r3_g_sum * 100, 2) / 5,\n", "                 round(reletive_r5_g_sum * 100, 2) / 5))\n", "    print(\" ndcg_delta@1: {}, \\n ndcg_delta@3: {}, \\n ndcg_delta@5: {}\".\n", "          format(round(reletive_n1_g_sum * 100, 2) / 5, round(reletive_n3_g_sum * 100, 2) / 5,\n", "                 round(reletive_n5_g_sum * 100, 2) / 5))\n", "    print(\" r@1: {},\\n r@3: {},\\n r@5: {}\".format(r1_sum / 5, r3_sum / 5, r5_sum / 5))\n", "    print(\" r_g@1: {},\\n r_g@3: {}, \\n r_g@5: {}\".format(r1_g_sum / 5, r3_g_sum / 5,\n", "                                                         r5_g_sum / 5))\n", "    print(\" ndcg@1: {},\\n ndcg@3: {},\\n ndcg@5: {}\".format(n1_sum / 5, n3_sum / 5, n5_sum / 5))\n", "    print(\" ndcg_g@1: {},\\n ndcg_g@3: {}, \\n ndcg_g@5: {}\".format(n1_g_sum / 5, n3_g_sum / 5,\n", "                                                                  n5_g_sum / 5))\n", "    print(\" r@1_c: {},\\n r@3_c: {},\\n r@5_c: {}\".format(r1_sum_c / 5, r3_sum_c / 5, r5_sum_c / 5))\n", "    print(\" r_g@1_c: {},\\n r_g@3_c: {}, \\n r_g@5_c: {}\".format(r1_g_sum_c / 5, r3_g_sum_c / 5,\n", "                                                               r5_g_sum_c / 5))\n", "    print(\" ndcg@1_c: {},\\n ndcg@3_c: {},\\n ndcg@5_c: {}\".format(n1_sum_c / 5, n3_sum_c / 5, n5_sum_c / 5))\n", "    print(\" ndcg_g@1_c: {},\\n ndcg_g@3_c: {}, \\n ndcg_g@5_c: {}\".format(n1_g_sum_c / 5, n3_g_sum_c / 5,\n", "                                                                        n5_g_sum_c / 5))\n", "    f = open(data_save_path, 'w')\n", "    f.write(json.dumps(selected_image))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}